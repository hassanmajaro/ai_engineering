{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e71200f",
   "metadata": {},
   "source": [
    "## **Understanding Numpy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e28610",
   "metadata": {},
   "source": [
    "* Numpy (Numerical Python) is the foundation library for scientific computing in Python. It provides a powerful N-dimesional array object and tools for working with these arrays.\n",
    "* Think of Numpy as the engine that powers most data science libraries - pandas uses Numpy arrays internally, scikit-learn expects Numpy arrays for machine learning, and matplotlib uses Numpy for plotting.\n",
    "* NumPy operations are implemented in C, making them 10-100x faster than pure Python\n",
    "* Numpy arrays store data more compactly than Python lists\n",
    "* Vectorization: Perform operations on entire arrays without writing loops\n",
    "* Work with arrays of different shapes seamlessly\n",
    "* Foundation for pandas, scikit-learn, matplotlib, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c130af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "# import all necessary libaries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "\n",
    "# check Numpy version\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "# Display settings for cleaner output\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc6787",
   "metadata": {},
   "source": [
    "We import Numpy with the standard alias `np`. The print options make arrays display more readably by limiting decimal places and avoding scientic notation for numbers like 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62901144",
   "metadata": {},
   "source": [
    "**Numpy Data Structure**\n",
    "* Numpy arrays are fundamentally different from Python lists:\n",
    "* Homogenous: All elements must be the same data type\n",
    "* Fixed size: Size is determined at creation (though you can create new arrays)\n",
    "* More efficient: Elements are stored in contiguous memory blocks\n",
    "* Vectorized operations: Mathematical operations work on entire arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0729312",
   "metadata": {},
   "source": [
    "**Creating Numpy Arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99f678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D array: [1 2 3 4 5]\n",
      "2D array:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "3D array:\n",
      " [[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n"
     ]
    }
   ],
   "source": [
    "# Creating arrays from Python lists\n",
    "# 1D array: A simple sequences of numbers\n",
    "arr1d = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# 2D array: Think of this as a matrix or table with rows and columns\n",
    "arr2d = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "# 3D array: Like a stack of 2D arrays - useful for images, time series, etc.\n",
    "arr3d = np.array([[[1, 2], [3, 4]],\n",
    "                  [[5, 6], [7, 8]]])\n",
    "\n",
    "print(\"1D array:\", arr1d)\n",
    "print(\"2D array:\\n\", arr2d)\n",
    "print(\"3D array:\\n\", arr3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e5aae9",
   "metadata": {},
   "source": [
    "When you pass a nested list to np.array(), NumPy automatically determines the dimensions. The 1D array is like a single row, 2D is like a spreadsheet, and 3D is like multiple spreadsheets stacked together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd705a2",
   "metadata": {},
   "source": [
    "**Creating Special Arrays in Numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0697ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros array (3x4): \n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "Ones array shape:  (2, 3, 4)\n",
      "Empty array (contains random values):\n",
      " [[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Creating arrays filled with zeros - useful for initializing arrays\n",
    "# Shape (3, 4) means 3 rows and 4 columns\n",
    "zeros = np.zeros((3, 4))\n",
    "\n",
    "# Creating arrays filled with ones = often used as starting points\n",
    "ones = np.ones((2, 3, 4))       # 3D array: 2 layers, 3 rows, 4 columns\n",
    "\n",
    "# Empty array - faster than zeros/ones but contains random values\n",
    "# Use when you'll immediatly fill the array with real data\n",
    "empty = np.empty((2, 2))\n",
    "\n",
    "print(\"Zeros array (3x4): \\n\", zeros)\n",
    "print(\"Ones array shape: \", ones.shape)\n",
    "print(\"Empty array (contains random values):\\n\", empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e4b68",
   "metadata": {},
   "source": [
    "`zeros()` and `ones()` are memory-efficient ways to create arrays of specific sizes. `empty()` is fastest but contains garbage values, so only use it when you'll immediately overwrite the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33202a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range array: [0 2 4 6 8]\n",
      "Linspace array: [0.   0.25 0.5  0.75 1.  ]\n",
      "Logspace array: [  1.      3.162  10.     31.623 100.   ]\n"
     ]
    }
   ],
   "source": [
    "# Range arrays - like Python's range() but more powerful\n",
    "range_arr = np.arange(0, 10, 2)     # start, stop, step: [0, 2, 4, 5, 8]\n",
    "print(\"Range array:\", range_arr)\n",
    "\n",
    "# Linearly spaced arrays - divide a range into equal parts\n",
    "# From 0 to 1 with exactly 5 points (including endpoints)\n",
    "linspace_arr = np.linspace(0, 1, 5)\n",
    "print(\"Linspace array:\", linspace_arr)\n",
    "\n",
    "# Logarithmically spaced arrays - useful for scientific data\n",
    "# From 10^0 to 10^2 (1 to 100) with 5 points\n",
    "logspace_arr = np.logspace(0, 2, 5)\n",
    "print(\"Logspace array:\", logspace_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df8fb28",
   "metadata": {},
   "source": [
    "* `arange()` works like Python's range() but returns a Numpy array and works with floats\n",
    "* `linspace()` divides a range into equal segments - useful for plotting smooth curves. \n",
    "* `logspace()` creates points that are evenly spaced on a logarithmic scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f14dd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identify matrix:\n",
      " [[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "Diagonal matrix:\n",
      " [[1 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 4]]\n",
      "Full array (filled with 7):\n",
      " [[7 7 7]\n",
      " [7 7 7]\n",
      " [7 7 7]]\n"
     ]
    }
   ],
   "source": [
    "# Identify matrix - diagonal of ones, zero elsewhere\n",
    "# Essential for linear algebra operations\n",
    "identity = np.eye(4)            # 4x4 identity matrix\n",
    "\n",
    "# Diagonal matrix - put values on the diagonal\n",
    "diagonal = np.diag([1, 2, 3, 4])\n",
    "\n",
    "# Array filled with a specific value\n",
    "full_arr = np.full((3, 3), 7)   # 3x3 array filled with 7\n",
    "\n",
    "print(\"Identify matrix:\\n\", identity)\n",
    "print(\"Diagonal matrix:\\n\", diagonal)\n",
    "print(\"Full array (filled with 7):\\n\", full_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40699245",
   "metadata": {},
   "source": [
    "Identity matrices are crucial in linear algebra - multiplying any matrix by identity matrix returns the original matrix. Diagonal matrices are useful for scaling operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168381b0",
   "metadata": {},
   "source": [
    "**Numpy Data Types (dtypes)**\n",
    "* Understanding data types is crucial for memory efficiency and numerical precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25764cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer array dtype: int32\n",
      "Float array dtype: float16\n",
      "Boolean array dtype: bool\n",
      "Converted array dtype: float32\n",
      "int32 uses 4 bytes per element\n",
      "float64 uses 2 bytes per element\n"
     ]
    }
   ],
   "source": [
    "# Explicit data types - control memory usage and precision\n",
    "int_arr = np.array([1, 2, 3], dtype=np.int32)       # 32-bit integers\n",
    "float_arr = np.array([1, 2, 3], dtype=np.float64)   # 64-bit floats (double precision)\n",
    "bool_arr = np.array([True, False, True], dtype=np.bool_)        # Boolean values\n",
    "\n",
    "# Type conversion - change dtype of existing array\n",
    "converted = int_arr.astype(np.float32)      # convert to 32-bit float\n",
    "\n",
    "print(\"Integer array dtype:\", int_arr.dtype)\n",
    "print(\"Float array dtype:\", float_arr.dtype)\n",
    "print(\"Boolean array dtype:\", bool_arr.dtype)\n",
    "print(\"Converted array dtype:\", converted.dtype)\n",
    "\n",
    "# Memory usage comparison\n",
    "print(f\"int32 uses {int_arr.itemsize} bytes per element\")\n",
    "print(f\"float64 uses {float_arr.itemsize} bytes per element\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae9746",
   "metadata": {},
   "source": [
    "* int8: 1byte, range - 128 to 127\n",
    "* int32: 4bytes, range +- 2billion\n",
    "* float32: 4 bytes, ~7 decimal digits precision\n",
    "* float64: 8 bytes, ~15 decimal digits precision\n",
    "* Choose smaller types to save memory, larger types for precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8558a5e",
   "metadata": {},
   "source": [
    "**Array Properties & Attributes**\n",
    "* Understanding array properties helps you work effectively with your data and debug issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b528f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3, 4, 5)\n",
      "Size: 60\n",
      "Ndim: 3\n",
      "Dtype: float64\n",
      "Itemsize: 8\n",
      "Memory usage: 480 bytes\n",
      "Memory usage: 0.46875 KB\n"
     ]
    }
   ],
   "source": [
    "# Create a sample 3D array for demonstration\n",
    "# Think of this as 3 layers, each with 4 rows and 5 columns\n",
    "arr = np.random.randn(3, 4, 5)\n",
    "\n",
    "# Shape: The dimensions of the array (layers, rows, colums)\n",
    "print(\"Shape:\", arr.shape)          # Output:  (3, 4, 5)\n",
    "\n",
    "# Size: Total number of elements (3 x 4 x 5 = 60)\n",
    "print(\"Size:\", arr.size)\n",
    "\n",
    "# Ndim: Number of dimensions (3D in this case)\n",
    "print(\"Ndim:\", arr.ndim)\n",
    "\n",
    "# Dtype: Data type of elements\n",
    "print(\"Dtype:\", arr.dtype)          # Usually float64 for random numbers\n",
    "\n",
    "# Itemsize: Memory size of each element in bytes\n",
    "print(\"Itemsize:\", arr.itemsize)        # 8 bytes for float64\n",
    "\n",
    "# Total memory usage in bytes\n",
    "print(\"Memory usage:\", arr.nbytes, \"bytes\")     # size x itemsize\n",
    "print(\"Memory usage:\", arr.nbytes / 1024, \"KB\")     # Convert to KB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a36a7ef",
   "metadata": {},
   "source": [
    "These properties are essential for understanding your data's structure and memory requirements. Large datasets require careful attention to memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a9325c",
   "metadata": {},
   "source": [
    "**Array Indexing & Slicing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70753f5",
   "metadata": {},
   "source": [
    "**Basic Indexing - Accessing Individual Elements**\n",
    "* NumPy indexing is similar to Python lists but more powerful for multi-dimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9b90893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element: 10\n",
      "Large element: 50\n",
      "Slice [1:4] [20 30 40]\n",
      "Every 2nd element: [10 30 50]\n"
     ]
    }
   ],
   "source": [
    "# 1D array indexing - similar to Python lists\n",
    "arr1d = np.array([10, 20, 30, 40, 50])\n",
    "\n",
    "print(\"First element:\", arr1d[0])       # Index 0: 10\n",
    "print(\"Large element:\", arr1d[-1])      # Negative indexing: 50\n",
    "print(\"Slice [1:4]\", arr1d[1:4])        # Elements 1, 2, 3: [20, 30, 40]\n",
    "print(\"Every 2nd element:\", arr1d[::2]) # step of 2: [10, 30, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392abbb4",
   "metadata": {},
   "source": [
    "Negative indices count from the end (-1 is last element). Slicing uses [start:stop:step] where stop is exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed8e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D array indexing - row and column access\n",
    "arr2d = np.array([[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8],\n",
    "                  [9, 10, 11, 12]])\n",
    "\n",
    "# Access specific element: [row, column]\n",
    "print(\"Element at row 1, column 2:\", arr2d[1, 2])       # 7\n",
    "\n",
    "# Access entire rows and columns\n",
    "print(\"First row:\", arr2d[0, :])                # all columns of row 0\n",
    "print(\"Second column:\", arr2d[:, 1])            # all rows of column 1\n",
    "\n",
    "# Subarray slicing: [row_start:row_end, col_start:col_end]\n",
    "print(\"Subarray (rows 1-2, cols 1-2:)\\n\", arr2d[1:3, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32997a9",
   "metadata": {},
   "source": [
    "The comma separates dimensions. : means \"all elements along this dimension\". Slicing creates views of the original data when possible, not copies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3006ac04",
   "metadata": {},
   "source": [
    "**Advanced Indexing - Powerful Selection Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21caf3fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (312130335.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\JOHN DOE\\AppData\\Local\\Temp\\ipykernel_21700\\312130335.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    arr = np.array([10, 20, 30, 40 50])\u001b[0m\n\u001b[1;37m                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fancy indexing - use arrays of indices to select elements\n",
    "arr = np.array([10, 20, 30, 40 50])\n",
    "indices = np.array([0, 2, 4])       # select elements at positioins 0, 2, 4\n",
    "print(\"Fancy indexing:\", arr[indices])          # [10, 30, 50]\n",
    "\n",
    "# This is much more flexible than simple slicing\n",
    "random_indices = np.array([4, 1, 3, 1])     # can repeat and reorder\n",
    "print(\"Random order:\", arr[random_indices])         # [50, 20, 40, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c39e3",
   "metadata": {},
   "source": [
    "Fancy indexing lets you select elements in any order, repeat elements, and select non-contiguous elements. Very useful for data sampling and reordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec22fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D fancy indexing - select specific row/column combinations\n",
    "arr2d = np.arange(12).reshape(3, 4)     # 3x4 array: [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]\n",
    "print(\"Original 2D array:\\n\", arr2d)\n",
    "\n",
    "# select elements at (row, col) pairs: (0,1) and (2, 3)\n",
    "rows = np.array([0, 2])\n",
    "cols = np.array([1, 3])\n",
    "print(\"Elements at (0,1) and (2,3):\", arr2d[rows, cols])        # [1, 11]\n",
    "\n",
    "# Select entire rows using fancy indexing\n",
    "selected_rows = arr2d[[0, 2], :]    # Rows 0 and 2, all columns\n",
    "print(\"Selected rows:\\n\", selected_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bffa47",
   "metadata": {},
   "source": [
    "When you provide arrays for both dimensions, NumPy pairs them element-wise. This is different from slicing, which creates a rectangular subarray."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698839b",
   "metadata": {},
   "source": [
    "**Array Reshaping & Manipulation**\n",
    "* Reshaping changes how the same data is organized in memory without changing the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3a2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a 1D array\n",
    "arr = np.arange(12)     # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "print(\"Original 1D array:\", arr)\n",
    "\n",
    "# Reshape to 2D: 3 rows x 4 columns\n",
    "reshaped_2d = arr.reshape(3, 4)\n",
    "print(\"Reshaped to 3x4:\\n\", reshaped_2d)\n",
    "\n",
    "# Reshape to 3D: 2 layers x 2 rows x 3 columns\n",
    "reshaped_3d = arr.reshape(2, 2, 3)\n",
    "print(\"Reshaped to 2x2x3:\\n\", reshaped_3d)\n",
    "\n",
    "# Use -1 to let NumPy calculate one dimension automatically\n",
    "auto_reshape = arr.reshape(4, -1)       # 4 rows, NumPy calculates columns\n",
    "print(\"Auto-reshaped to 4x?:\\n\", auto_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de0e4f",
   "metadata": {},
   "source": [
    "The total number of elements must remain the same (12 in this case). Using -1 tells NumPy to calculate that dimension automatically. Reshaping creates a view when possible, not a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca897f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening - convert multi-dimensional array to 1D\n",
    "arr2d = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# flatten() always returns a copy\n",
    "flattened = arr2d.flatten()\n",
    "\n",
    "# ravel() returns a view if possible (faster, memory efficient)\n",
    "ravel = arr2d.ravel()\n",
    "print(\"Ravel (view if possible:)\", ravel)\n",
    "\n",
    "# Demonstrates the difference\n",
    "arr2d[0, 0] = 999\n",
    "print(\"After modifying original:\")\n",
    "print(\"Flattend (unchanged:)\", flattened)       # copy is independent\n",
    "print(\"Ravel (changed):\", ravel)            # view reflects changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a47bf",
   "metadata": {},
   "source": [
    "Use `ravel()` when you don't need to modify the flattened array independently. Use `flatten()` when you need a separate copy that won't be affected by changes to the original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a839e",
   "metadata": {},
   "source": [
    "**Transposing and Swapping Axes**\n",
    "*Transposing is essential for matrix operations and changing data orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059bca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D transposition - flip rows and columns\n",
    "arr2d = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "print(\"Original shape:\", arr2d.shape)       # (2, 3)\n",
    "print(\"Original:\\n\", arr2d)\n",
    "\n",
    "print(\"Transposed shape:\", arr2d.T.shape)       # (3, 2)\n",
    "print(\"Transposed:\\n\", arr2d.T)\n",
    "\n",
    "# Alternative transpose methods\n",
    "print(\"Transpose method:\\n\", arr2d.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63f051",
   "metadata": {},
   "source": [
    "Transposing swaps rows and columns. This is crucial for matrix multiplication and when you need to change data orientation (e.g., from samplesxfeatures to featuresxsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ea7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher-dimensional transposition\n",
    "arr3d = np.arange(24).reshape(2, 3, 4)  # 2 layers, 3 rows, 4 columns\n",
    "\n",
    "# specify new axis order: (axis0, axis1, axis2) -> (axis2, axis0, axis1)\n",
    "transposed_3d = arr3d.transpose(2, 0, 1)\n",
    "print(\"Transposed 3D shape:\", transposed_3d.shape)      # (4, 2, 3)\n",
    "\n",
    "# moveaxis is another way to rearrange axes\n",
    "moved = np.moveaxis(arr3d, 0, -1)     # Move first axis to last position\n",
    "print(\"Moveaxis result shape:\", moved.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bceb77a",
   "metadata": {},
   "source": [
    "For 3D+ arrays, you specify the new order of axes. This is useful for reshaping data for different algorithms or visualization requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efe004",
   "metadata": {},
   "source": [
    "**Concatenating and Splitting Arrays**\n",
    "* Combining and dividing arrays is fundamental for data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff40c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation - joining arrays along existing axes\n",
    "arr1 = np.array([[1, 2], [3, 4]])\n",
    "arr2 = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "# Concatenate along different axes\n",
    "concat_rows = np.concatenate([arr1, arr2], axis=0)  # stack vertically\n",
    "concat_cols = np.concatenate([arr1, arr2], axis=1)  # stack horizontally\n",
    "\n",
    "print(\"Original arrays:\")\n",
    "print(\"Array 1:\\n\", arr1)\n",
    "print(\"Array 2:\\n\", arr2)\n",
    "print(\"Concatenated vertically (axis=0):\\n\", concat_rows)\n",
    "print(\"Concatenated horizontally (axis=1):\\n\", concat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b9d72",
   "metadata": {},
   "source": [
    "`axis=0` means along rows (vertical stacking), `axis=1` means along columns (horizontal stacking). Arrays must have compatible shapes along the non-concatenated dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffccb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenient stacking functions\n",
    "vstack_result = np.vstack([arr1, arr2]) # same as concatenate with axis=0\n",
    "hstack_result = np.hstack([arr1, arr2]) # same as concatenate with axis=1\n",
    "dstack_result = np.dstack([arr1, arr2]) # stack along depth (3rd dimension)\n",
    "\n",
    "print(\"vstack (vertical):\\n\", vstack_result)\n",
    "print(\"hstack (horizontal): \\n\", hstack_result)\n",
    "print(\"dstack shape:\", dstack_result.shape)     # creates 3D array\n",
    "\n",
    "# Splitting arrays - opposite of concatenation\n",
    "arr = np.arange(12).reshape(3, 4)\n",
    "split_arrys = np.split(arr, 3, axis=0)      # split into 3 parts along rows\n",
    "print(\"Original array for splitting:\\n\", arr)\n",
    "print(\"Split into 3 parts along rows:\")\n",
    "for i, split_part in enumerate(split_arrays):\n",
    "    print(f\"Part {i}:\\n\", split_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f969a707",
   "metadata": {},
   "source": [
    "Stacking functions are shortcuts for concatenation. Splitting divides an array into equal parts - useful for creating training/validation sets or processing in data chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ee300",
   "metadata": {},
   "source": [
    "**Mathematical Operations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f412ef",
   "metadata": {},
   "source": [
    "**Element-wise Operations - The Power of Vectorization**\n",
    "* NumPy's biggest advantage is performing operations on entire arrays without writing loo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6375b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic arithmetic operations work element-by-element\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([10, 20, 30, 40])\n",
    "\n",
    "print(\"Array 1:\", arr1)\n",
    "print(\"Array 2:\", arr2)\n",
    "\n",
    "# All operations happen element-wise automatically\n",
    "print(\"Addition:\", arr1 + arr2)         # [11, 22, 33, 44]\n",
    "print(\"Subtraction:\", arr2 - arr1)      # [9, 18, 27, 36]\n",
    "print(\"Multiplication:\", arr1 * arr2)   # [10, 40, 90, 160]\n",
    "print(\"Divison:\", arr2 / arr1)          # [10, 10, 10, 10]\n",
    "print(\"Power:\", arr1 ** 2)              # [1, 4, 9, 16]\n",
    "print(\"Modulo:\", arr2 % 3)              # [1, 2, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdfcacd",
   "metadata": {},
   "source": [
    "This vectorization is much faster than Python loops because the operations are implemented in optimized C coce. Each operation applies to corresponding elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc65464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations with scalars - broadcasting in action\n",
    "print(\"Scalar operations:\")\n",
    "print(\"Add 10 to all elements:\", arr1 + 10)     # [11, 12, 13, 14]\n",
    "print(\"Multiply all by 3:\", arr1 * 3)           # [3, 6, 9, 12]\n",
    "print(\"Divide all by 2:\", arr1 / 2)         # [0.5, 1, 1.5, 2]\n",
    "\n",
    "# Compound operations\n",
    "result = (arr1 + 5) * 2 - 1         \n",
    "print(\"Compound operation (arr1 + 5) * 2 - 1:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17c4ed",
   "metadata": {},
   "source": [
    "When you operate on arrays with scalars, the scalar is automatically \"broadcast\" to match the array shape. This much more readable and efficient that manual loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051864f2",
   "metadata": {},
   "source": [
    "**Mathematical Functions - Beyond Basic Arithmetic**\n",
    "* NumPy provides vectorized versions of most mathematical function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4888edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common mathematical functions\n",
    "arr = np.array([1, 4, 9, 16, 25])\n",
    "print(\"Original array:\", arr)\n",
    "\n",
    "# Square roots and powers\n",
    "print(\"Square root:\", np.sqrt(arr))         # [1, 2, 3, 4, 5]\n",
    "print(\"Square:\", np.square(arr))            # [1, 16, 81, 256, 625]\n",
    "print(\"Cube root:\", np.cbrt(arr))\n",
    "\n",
    "# Exponential and logarithmic functions\n",
    "small_arr = np.array([1, 2, 3])\n",
    "print(\"Exponential:\", np.exp(small_arr))    # [e^1, e^2, e^3]\n",
    "print(\"Natural log:\", np.log(arr))          # ln(arr)\n",
    "print(\"Log base 10:\", np.log10(arr))\n",
    "print(\"Log base 2:\", np.log2(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac47b3",
   "metadata": {},
   "source": [
    "These functions are much faster than applying Python's math functions in a loop. They also handle edge cases (like log of zero) more gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f48c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigonometric functions - essential for signal processing and geometry\n",
    "angles = np.array([0, np.pi/4, np.pi/2, np.pi])\n",
    "print(\"Angles (radians):\", angles)         \n",
    "print(\"Sine:\", np.sin(angles))              # [0, v2/2, 1, 0]\n",
    "print(\"Cosine:\", np.cos(angles))            # [1, v2/2, 0, -1]\n",
    "print(\"Tangent:\", np.tan(angles))           # [0, 1, infinite, 0]\n",
    "\n",
    "# Convert degrees to radians\n",
    "degrees = np.array([0, 45, 90, 100])\n",
    "radians = np.deg2rad(degrees)\n",
    "print(\"Degrees to radians:\", radians)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00c1816",
   "metadata": {},
   "source": [
    "Trigonometric functions expect angles in radians. Use `deg2rad()` and `rad2deg()` for conversions. These functions are essential for signal processing, computer graphics, and physics simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding and comparison functions\n",
    "decimals = np.array([1.234, ,5.678, 9.999, -2.345])\n",
    "print(\"Original decimals:\", decimals)\n",
    "\n",
    "print(\"Round to 2 places:\", np.round(decimals, 2))\n",
    "print(\"Floor (round down):\", np.floor(decimals))        # [1, 5, 9, -3]\n",
    "print(\"Ceiling (round up):\", np.ceil(decimals))         # [2, 6, 10, -2]\n",
    "print(\"Truncate (toward zero):\", np.trunc(decimals))    # [1, 5, 9, -2]\n",
    "\n",
    "# Absolute values and sign\n",
    "print(\"Absolute values:\", np.abs(decimals))\n",
    "print(\"Sign (-1, 0, or 1):\", np.sign(decimals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94542298",
   "metadata": {},
   "source": [
    "Different rounding functions serve different purposes. `floor()` always rounds down, `ceil()` always rounds up, `trunc()` removes the decimal part, and `round()` rounds to nearest value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8671a",
   "metadata": {},
   "source": [
    "**Aggregate Functions - Summarizing Your Data**\n",
    "- Aggregate functions reduce arrays to summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8020ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D array for demonstration\n",
    "arr = np.array([[1, 2, 3],\n",
    "                [4, 5, 6]\n",
    "                [7, 8, 9]])\n",
    "print(\"Sample array:\\n\", arr)\n",
    "\n",
    "# Aggregation across entire array\n",
    "print(\"Sum of all elements:\", np.sum(arr))      # 45\n",
    "print(\"Mean of all elements:\", np.mean(arr))    # 5.0\n",
    "print(\"Standard deviationi:\", np.std(arr))      # 2.58\n",
    "print(\"Minimum value:\", np.min(arr))            # 1\n",
    "print(\"Maximum value:\", np.max(arr))            # 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3557fd62",
   "metadata": {},
   "source": [
    "When you don't specify an axis, these functions operate on the flattened array, giving you a single summary value for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac92eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axis-specific aggregatioin - this is where NumPy shines!\n",
    "print(\"Sum along axis 0 (columns):\", np.sum(arr, axis=0))       # [12, 15, 18]\n",
    "print(\"Sum along axis 1 (rows):\", np.sum(arr, axis=1))          # [6, 16, 24]\n",
    "\n",
    "print(\"Mean along axis 0:\", np.mean(arr, axis=0))               # [4, 5, 6]\n",
    "print(\"Mean along axis 1:\", np.mean(arr, axis=1))               # [2, 5, 8]\n",
    "\n",
    "# Finding position of extreme values\n",
    "print(\"Position of max (flattened):\", np.argmax(arr))       # 8 (element 9 at position 8)\n",
    "print(\"Position of max along axis 0:\", np.argmax(arr, axis=0))  # [2, 2, 2]\n",
    "print(\"Position of max along axis 1:\", np.argmax(arr, axis=1))  # [2, 2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f7de2",
   "metadata": {},
   "source": [
    "* `axis=0`: Operations go \"down\"the rows (result has same number of columns)\n",
    "* `axis=1`: Operations go \"across\" the columns (result has same number of rows)\n",
    "* `argmax/argmin` return indices, not values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb610c",
   "metadata": {},
   "source": [
    "**Broadcasting**\n",
    "* Broadcasting is NumPy's way of performing operations on arrays with different shapes without explicitly reshaping them. This is one of NumPy's most powerful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3136562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcasting examples - arrays don't need the same shape!\n",
    "scalar = 5\n",
    "arr1d = np.array([1, 2, 3, 4])\n",
    "arr2d = np.array([[10], [20], [30]])        # column vector\n",
    "\n",
    "print(\"Scalar:\", scalar)\n",
    "print(\"1D array:\", arr1d)\n",
    "print(\"2D array (column vector):\\n\", arr2d)\n",
    "\n",
    "# Scalar broadcasts to any shape\n",
    "result1 = scalar + arr1d \n",
    "print(\"Scalar + 1D array:\", result1)       # [6, 7, 8, 9]\n",
    "\n",
    "# 2D + 1D broadcasting\n",
    "result2 = arr2d + arr1d \n",
    "print(\"2D + 1D broadcasting:\\n\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e681a04",
   "metadata": {},
   "source": [
    "* Broadcasting follows these rules:\n",
    "* Start from the trailing (rightmost) dimensions\n",
    "* Dimensions are compatible if they're equal or one is 1\n",
    "* Missing dimensions are assumed to be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing broadcasting step by step\n",
    "a = np.arange(4).reshape(4, 1)          # Shape: (4, 1)\n",
    "b = np.arange(5).reshape(1, 5)          # Shape: (1, 5)\n",
    "\n",
    "print(\"Array a (4x1):\\n\", a)\n",
    "print(\"Array b (1x5):\\n\", b)\n",
    "\n",
    "# Broadcasting creates a 4x5 result\n",
    "result = a + b                      # Result shape: (4, 5)\n",
    "print(\"Broadcasting result (4x5):\\n\", result)\n",
    "print(\"Result shape:\", result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c873e",
   "metadata": {},
   "source": [
    "Array `a` gets broadcast horizontally, array `b` gets broadcast vertically. This creates all pairwise combinations without storing redundant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57478c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual broadcasting with newaxis\n",
    "arr = np.array([1, 2, 3])\n",
    "print(\"Original array shape:\", arr.shape)           # (3,)\n",
    "\n",
    "# Convert to column vector\n",
    "column_vector = arr[:, np.newaxis]              # same as arr.reshape(-1, 1)\n",
    "print(\"Column vector shape:\", column_vector.shape)      # (3, 1)\n",
    "print(\"Column vector:\\n\", column_vector)\n",
    "\n",
    "# Convert to row vector (usually not needed - 1D arrays broadcast as rows)\n",
    "row_vector = arr[np.newaxis, :]         # same as arr.reshape(1, -1)\n",
    "print(\"Row vector shape:\", row_vector.shape)        # (1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97f1c4",
   "metadata": {},
   "source": [
    "`np.newaxis` is an alias for None and adds a new axis of length 1. This gives you explicit control over broadcasting behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0383eba3",
   "metadata": {},
   "source": [
    "**Common Broadcasting Patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f192a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Centering data (subtract mean from each column)\n",
    "data = np.random.randn(5, 3)        # 5 samples, 3 features\n",
    "print(\"Original data shape:\", data.shape)\n",
    "print(\"Original data:\\n\", data)\n",
    "\n",
    "# Calculate mean for each column\n",
    "column_means = np.mean(data, axis=0)        # Shape: (3,)\n",
    "print(\"Column means:\", column_means)\n",
    "\n",
    "# Subtract mean from each column (broacasting!)\n",
    "centered_data = data - column_means         # (5, 3) - (3,) broadcast\n",
    "print(\"Centered data:\\n\", centered_data)\n",
    "print(\"New column means (should be ~0):\", np.mean(centered_data, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9925072b",
   "metadata": {},
   "source": [
    "This is a common  preprocessing step in machine learning. The column means broadcast across all rows automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e72c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patern 2: Normalizing by row sums (useful for probabilities)\n",
    "data = np.random.rand(4, 3)         # Ramdom data\n",
    "print(\"Random data:\\n\", data)\n",
    "\n",
    "# Calculate row sums\n",
    "row_sums = np.sum(data, axis=1, keepdims=True)      # Shape: (4, 1)\n",
    "print(\"Row sums shape:\", row_sums.shape)\n",
    "print(\"Row sums:\\n\", row_sums)\n",
    "\n",
    "# Normalize each row to sum to 1\n",
    "normalized = data / row_sums                    # (4, 3) / (4,1) broadcasts\n",
    "print(\"Normalized data (rows sum to 1):\\n\", normalized)\n",
    "print(\"Row sums after normalization:\", np.sum(normalized, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614560cf",
   "metadata": {},
   "source": [
    "`keepdims=True` preserves the dimension at size 1, making broadcasting explicit and avoiding shape errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_module",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
