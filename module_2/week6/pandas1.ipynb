{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e72d6cef",
   "metadata": {},
   "source": [
    "# Groups of Functions in Pandas for Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df039fa0",
   "metadata": {},
   "source": [
    "### A. Creating Series and DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb56cf14",
   "metadata": {},
   "source": [
    "* I believe that we have learnt list and dictionary data structures when we were learning python. Now, we want to learn how to use both list and dictionaries for creating Pandas Series and DataFrames.\n",
    "\n",
    "\n",
    "**Creating a Pandas Series**\n",
    "\n",
    "To do anything with pandas, the first thing to do is to import the pandas library as an alias.\n",
    "\n",
    "* importing pandas package\n",
    "```c\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "* Creating pandas series\n",
    "```c\n",
    "series = pd.Series(data)\n",
    "```\n",
    "\n",
    "* Creating pandas DataFrame\n",
    "```c\n",
    "dataframe = pd.DataFrame(data)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad2d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a pandas Series using a python list\n",
    "\n",
    "#Step 1: Import pandas package\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#Step2: Define a list\n",
    "data = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "\n",
    "#Step3: Create the series\n",
    "series = pd.Series(data)\n",
    "\n",
    "# lets view the series that we have created\n",
    "series.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets confirm to be sure we had created a pandas series\n",
    "type(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d37fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a series using the same list, but now we will be adding our own serial numbering, in python or pandas it is called index\n",
    "series2 = pd.Series(data, index = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\"])\n",
    "series2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64396c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a series using python dictionary\n",
    "\n",
    "\n",
    "#lets create a python dictionary\n",
    "data2 = {'a': 10, 'b': 20, 'c': 30}\n",
    "\n",
    "# lets create the series\n",
    "series3 = pd.Series(data2)\n",
    "series3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a636a",
   "metadata": {},
   "source": [
    "__________________________________________________\n",
    "**Hands on practice**:\n",
    "1. Create a bucket list of 6 items. Convert the list to pandas series and define index for it using alphabets.\n",
    "2. Create a simple python dictionary of your biodata with 5 keys and their corresponding values. Convert the dictionary into a pandas series.\n",
    "\n",
    "_depending on where you are viewing this notebook you are either to download it or make a copy._\n",
    "________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded5eea",
   "metadata": {},
   "source": [
    "**Creating a DataFrame**\n",
    "\n",
    "\n",
    "  ```c\n",
    "  import pandas as pd\n",
    "  ```\n",
    "* Create your list of list or dictionary\n",
    "```c\n",
    "data = []\n",
    "#or\n",
    "data = {}\n",
    "```\n",
    "* Create the dataframe using this syntax\n",
    "```c\n",
    "df = pd.DataFrame(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LEts create a dataframe\n",
    "#Step1: import pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the data using dictionary that is having its values as a list.\n",
    "\n",
    "data = {\n",
    "    'Name': ['Chris', 'Ayo', 'Chisom'],\n",
    "    'Age': [26, 24, 22],\n",
    "    'Home_Town': ['Benin', 'Ibadan', 'Enugu']\n",
    "}\n",
    "\n",
    "# Lets create the dataframe using \"df\" as short for dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do the samething by using list of dictionaries\n",
    "data2 = [\n",
    "    {'Name': 'Chris', 'Age': 26, 'Home_Town': 'Benin'},\n",
    "    {'Name': 'Ayo', 'Age': 24, 'Home_Town': 'Ibadan'},\n",
    "    {'Name': 'Chisom', 'Age': 22, 'Home_Town': 'Enugu'}\n",
    "]\n",
    "# LEts define the dataframe\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b90292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do the sanething again using list of list\n",
    "\n",
    "data3 = [\n",
    "    ['Chris', 26, 'Benin'],\n",
    "    ['Ayo', 24, 'Ibadan'],\n",
    "    ['Chisom', 22, 'Enugu']\n",
    "]\n",
    "df3 = pd.DataFrame(data3, columns=['Name', 'Age', 'Home_Town'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c076f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets print the types to be sure we have defined dataframes\n",
    "print(type(df))\n",
    "print(type(df2))\n",
    "print(type(df3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220b453",
   "metadata": {},
   "source": [
    "**Hands on practice**\n",
    "\n",
    "* **Creating a dataset:**\n",
    "\n",
    "Lets create a google sheet, make the link accessible to everyone to input the following information First_Name, Last_Name, Gender, Seat_No, City, Course_Track, PC_make, PC_Os, and Feedback.\n",
    "\n",
    "\n",
    "[Click here to respond](https://forms.gle/8VQgWmvqQyiPEifY8)\n",
    "\n",
    "At the end of the collection, we will use the data to practice data manipulation.\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2b1382",
   "metadata": {},
   "source": [
    "### B. Data Input and Output:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b7ea7",
   "metadata": {},
   "source": [
    "**To read in datasets we use**\n",
    "```c\n",
    "pd.read_csv() # for csv files\n",
    "```\n",
    "\n",
    "```c\n",
    "pd.read_excel() # for excel files\n",
    "```\n",
    "**Note**: There are many other methods for reading in different data files based on their extensions. we have .json, .txt, .sql, .html etc. If you are curious you could check them out.\n",
    "\n",
    "\n",
    "**To save into csv file or excel file**\n",
    "\n",
    "```c\n",
    "df.to_csv()\n",
    "\n",
    "```\n",
    "To save to excel\n",
    "```c\n",
    "df.to_excel()\n",
    "```\n",
    "Usecase example\n",
    "```c\n",
    "bio_data.to_csv(\"bio_data.csv\", index = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6374737",
   "metadata": {},
   "source": [
    "Here, we would download our generated data in csv format and in excel format. Then load it using the `pd.read_csv()`\n",
    "\n",
    "Then we would inspect and explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe508516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lets get to work...\n",
    "# df = pd.read_csv('bio_data.csv')\n",
    "# df.head()\n",
    "\n",
    "# # Ensure to code along..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6673602",
   "metadata": {},
   "source": [
    "### C. Data Inspection and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36780c7",
   "metadata": {},
   "source": [
    "To inspect our dataset we will beusing the following python methods\n",
    "```c\n",
    ".head() # To view the first 5 rows\n",
    "```\n",
    "\n",
    "```c\n",
    ".tail() # To view the last 5 rows\n",
    "```\n",
    "\n",
    "```c\n",
    ".info() # To check the information about the data\n",
    "```\n",
    "\n",
    "```c\n",
    ".describe() # statistical summary\n",
    "```\n",
    "\n",
    "```c\n",
    ".shape # Check the dimension of the dataset\n",
    "```\n",
    "\n",
    "```c\n",
    ".columns # for checking the column names\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEts use all of this methods on our data\n",
    "\n",
    "\n",
    "\n",
    "# Please, ensure to code along"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e4d7a5",
   "metadata": {},
   "source": [
    "### D. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c72f2",
   "metadata": {},
   "source": [
    " Data cleaning involves identifying and handling errors or inconsistencies in your dataset. Later in this course, data cleaning would be handled in datails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0456cc0",
   "metadata": {},
   "source": [
    "Handling Missing Values\n",
    "\n",
    "```c\n",
    ".isna() or .isnull() # Check for missing values\n",
    "```\n",
    "\n",
    "```c\n",
    ".isna().sum()  # Check the total number of all missing values\n",
    "```\n",
    "\n",
    "```c\n",
    ".fillna() # Fill up missing values\n",
    "```\n",
    "\n",
    "```c\n",
    ".dropna() # Drop missing values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f437e",
   "metadata": {},
   "source": [
    "Finding and Handling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5bd7b3",
   "metadata": {},
   "source": [
    "Duplicated are repeated rows or columns.\n",
    "\n",
    "```c\n",
    "df.duplicated() # This checks if there are duplicates\n",
    "```\n",
    "\n",
    "```c\n",
    "df.drop_duplicated() # This is use for dropping the duplicate  values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb7562",
   "metadata": {},
   "source": [
    "Correcting Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b373225",
   "metadata": {},
   "source": [
    "In pandas there are two main types of datatypes, \"integer\" and \"Object\"\n",
    "\n",
    "You can check data type using\n",
    "```c\n",
    "\n",
    "df.dtype()\n",
    "```\n",
    "\n",
    "To convert the type of perform type casting, you use\n",
    "\n",
    "```c\n",
    "df.astype() # this takes in the datatype you want to convert it to as an argument\n",
    "```\n",
    "\n",
    "When working with time or time series dat its important to convert the time to pandas recognized time using\n",
    "\n",
    "```c\n",
    "pd.to_datatime() # takes in the data column as an argument\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb377598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have any missing values? if yes,lets fill them up\n",
    "\n",
    "\n",
    "bio_data.isna().sum()\n",
    "\n",
    "\n",
    "# Ensure to code along"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fca595",
   "metadata": {},
   "source": [
    "### E. Data Selection and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232caeab",
   "metadata": {},
   "source": [
    "Viewing data column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bio_data_column = [irst_Name, Last_Name, City, Course_Track, PC_make, PC_Os, Feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fce2af",
   "metadata": {},
   "source": [
    "Column selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32850ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look through a single column\n",
    "bio_data['First_Name']\n",
    "\n",
    "# alternatively, we can use dot\n",
    "bio_data.First_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4309e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEts select multiple columns\n",
    "bio_data[['First_Name', 'Last_Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets select more columns\n",
    "bio_data[['First_Name', 'City', 'Feedback']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6c5dd",
   "metadata": {},
   "source": [
    "Cell Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff0c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets select a single cell\n",
    "\n",
    "bio_data['First_Name'][0] # This will return the first value of the \"First_Name\" column\n",
    "\n",
    "# lets try other methods for selecting cells\n",
    "bio_data.at[0, \"First_Name\"] # This will also return the first value of the \"First_Name\" column\n",
    "\n",
    "\n",
    "# There is still another method using .iat[]\n",
    "bio_data.iat[0, 0] # This will return the first value of the first column(row0,column0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2bbcf",
   "metadata": {},
   "source": [
    "Row selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce109522",
   "metadata": {},
   "source": [
    "`iloc` is used to select rows/columns or rows and column using index slicing.\n",
    "This is very useful especially when your data bset do not have labels(that is, row names and column names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d486d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets select some rows\n",
    "bio_data.iloc[0:5] # we are selecting from index 0 to the 5th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7122385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of row and column selection\n",
    "bio_data.iloc[0:5, 0:3] # the first slice picks the rows and the second slice picks the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3ae49",
   "metadata": {},
   "source": [
    "___________________________________________________\n",
    "**Hands on practice**\n",
    "\n",
    "Find out when and how to use the `.loc` attribute. And apply it to the dataset.\n",
    "_________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4e7b1",
   "metadata": {},
   "source": [
    "Conditional Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34007fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where Gender is 'Female'. This is going to return dataframe\n",
    "filtered_male = bio_data2[bio_data2['Gender'] == 'Male']\n",
    "print(\"Rows where Gender is 'Male':\")\n",
    "filtered_male\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84288a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where City is 'Lagos' and Course_Track is 'Data Science'\n",
    "filtered_city = bio_data2[(bio_data2['City'] == 'Lagos') & (bio_data2['Course_Track'] == 'Data Science')]\n",
    "print(\"Rows where City is 'Lagos' and Course_Track is 'Data Science':\")\n",
    "filtered_city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0aa4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where City is either 'Lagos' or 'Abuja'\n",
    "cities = ['Lagos', 'Abuja']\n",
    "city_filtered = bio_data2[bio_data2['City'].isin(cities)]\n",
    "print(\"Rows where City is either 'Lagos' or 'Abuja':\")\n",
    "city_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa187926",
   "metadata": {},
   "source": [
    "Using the .query() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7457ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use query() to filter rows where Course_Track is 'AI' and Feedback is 'Excellent'\n",
    "query_filtered = bio_data2.query(\"Course_Track == 'AI' and Feedback == 'Excellent'\")\n",
    "print(\"Rows filtered using query() method:\")\n",
    "query_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec79906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where Course_Track is 'Data Science'\n",
    "data_science = bio_data2.query(\"Course_Track == 'Data Science'\")\n",
    "print(\"Students in the Data Science track:\")\n",
    "data_science\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cbddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows using multiple conditions with logical operators\n",
    "webdev_high_seat_No = bio_data2.query(\"Seat_No > 110 and Course_Track == 'Web Dev'\")\n",
    "print(\"Web Dev students with Seat_No greater than 110:\")\n",
    "webdev_high_seat_No\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where PC_make is either 'HP' or 'Dell'\n",
    "hp_dell = bio_data2.query(\"PC_make in ['HP', 'Dell']\")\n",
    "print(\"Rows where PC_make is either HP or Dell:\")\n",
    "hp_dell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d74969a",
   "metadata": {},
   "source": [
    "Sometimes we may want to use a Python variable inside our query. It can be done by prefixing the variable with an @ symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable for the course track\n",
    "desired_track = 'Cloud Computing'\n",
    "\n",
    "# Use the variable in the query expression\n",
    "cloud_computing_students = bio_data2.query(\"Course_Track == @desired_track\")\n",
    "print(\"Students in the Cloud Computing track:\")\n",
    "cloud_computing_students\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb6a263",
   "metadata": {},
   "source": [
    "Lets filter rows where the Feedback is not \"Poor\" and the City is \"Lagos\". Use the != operator for negation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where Feedback is not 'Poor' and City is 'Lagos'\n",
    "good_feedback_lagos = bio_data2.query(\"Feedback != 'Poor' and City == 'Lagos'\")\n",
    "print(\"Students in Lagos with Feedback other than 'Poor':\")\n",
    "good_feedback_lagos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEts create a more complex query filter for Course_Track,Feedback and Seat_No\n",
    "complex_query = bio_data2.query(\"Course_Track == 'Data Science' or (Feedback == 'Excellent' and Seat_No < 115)\")\n",
    "print(\"Complex query result:\")\n",
    "complex_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c6ae6",
   "metadata": {},
   "source": [
    "### F. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba1508e",
   "metadata": {},
   "source": [
    "Renaming Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets modify the column names by fixing the old names as keys and the new name as values\n",
    "bio_data.rename(columns={'First_Name': 'FirstName', 'Last_Name': 'LastName'})\n",
    "\n",
    "# You can try renaming all the columns by removing all the underscores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd961b0c",
   "metadata": {},
   "source": [
    "Applying String Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9698e",
   "metadata": {},
   "source": [
    "The `.str` is a string accessor used along siide with the normal methods for manipuating strings such as `.upper()`, `.lower()`, `.ttitle()` etc.\n",
    "\n",
    "But lets see how they are combined;\n",
    "\n",
    "```c\n",
    ".str.upper() # This converts to upper cases or capital letter\n",
    "```\n",
    "\n",
    "```c\n",
    ".str.lower() # This converts to lower cases or small letters\n",
    "```\n",
    "\n",
    "\n",
    "```c\n",
    ".str.title() # This converts to title cases or capitalize first letter of each word\n",
    "```\n",
    "\n",
    "\n",
    "```c\n",
    ".str.strip() # This removes white space before and after a string\n",
    "```\n",
    "\n",
    "\n",
    "```c\n",
    ".str.split() # This splits an iterable into its component parts such as splitting a word into letters and splitting sentences into words using a delimiter.\n",
    "```\n",
    "\n",
    "```c\n",
    ".str.len() # This is used to check the length of an iterable.\n",
    "```\n",
    "\n",
    "\n",
    "```c\n",
    ".str.replace() # This is similar to the find and replace method in excel. It is used for replacing a strings.\n",
    "```\n",
    "\n",
    "\n",
    "```c\n",
    ".str.contains() # This checks if a substrinng is available in a string\n",
    "```\n",
    "\n",
    "\n",
    "```c\n",
    ".str.join() # This is used to join elements of a list into a single string.\n",
    "```\n",
    "\n",
    "```c\n",
    ".str.slice() # This is used to slice strings at a specied index position\n",
    "```\n",
    "All of these methods will come very handing during data cleaning and data preprocessing for text data.\n",
    "\n",
    "Lets apply some of the string methods.\n",
    "\n",
    "**Note**: To apply some to the entire dataset, we have to define a function(lambda function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets apply some of the methods to our dataset\n",
    "bio_data[\"Feedback\"] = bio_data[\"Feedback\"].str.lower() # Here we are converting  everything to small letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4925fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert the \"PC_Os\" to upper case\n",
    "bio_data[\"PC_Os\"] = bio_data[\"PC_Os\"].str.upper() # Here we are converting  everything to small letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec2e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets convert the \"First_Name\"\n",
    "bio_data[\"First_Name\"] = bio_data[\"First_Name\"].str.title() # Here we are converting the first letters to capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEts view to see if it has applied\n",
    "bio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2013ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEts define a lambda function\n",
    "lambda x: x.str.title()\n",
    "\n",
    "# The .apply() method will help apply the function to the selected columns\n",
    "\n",
    "bio_data[col] bio_data[col].apply(lambda x: x.str.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEts view to see if it has applied\n",
    "bio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a703e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can decide to apply the lambda funtion to every element in the dataset\n",
    "bio_data.applymap(lambda x: x.str.title())\n",
    "bio_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5e18f",
   "metadata": {},
   "source": [
    "**Assignment**\n",
    "\n",
    "1. Do a research on `.str.nomalize()` method. Write a 100 words summary of your findings.\n",
    "\n",
    "2. Look for a accented yoruba text data online, apply the `str.normalize()` method on the dataset and submit before next class.\n",
    "3. Try out other string operations for tranforming text or string data listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac80365",
   "metadata": {},
   "source": [
    "Sorting Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9343eb",
   "metadata": {},
   "source": [
    "You can use the `.sort_values()` to sort the dataframe by one or multiple columns.\n",
    "\n",
    "Below is a typical example of how to use `sort_values()`\n",
    "```c\n",
    "bio_data.sort_values(by, axis=1, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False)\n",
    "\n",
    "# in pandas, axis 0 represents rows\n",
    "# axis 1 represents columns\n",
    "# inplace= True, makes the change permament\n",
    "# na_position = \"first\", signifies where to put the Nan values\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954011ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting columns\n",
    "bio_data.sort_values(by='City', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46f1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets sort by multiple columns\n",
    "bio_data.sort_values(by=['City', 'PC_make'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae7b11",
   "metadata": {},
   "source": [
    "Sorting by row labels or index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf24d64",
   "metadata": {},
   "source": [
    "To sort the dataframe by its index or row label the `.sort_index()` method is used.\n",
    "\n",
    "How to use `.sort_index()` method\n",
    "\n",
    "```c\n",
    "bio_data.sort_index(axis = 0, level = None, ascending = False, inplace = False, sort_remaining = True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb91dc62",
   "metadata": {},
   "source": [
    "**If you are curious...try experimenting with this..**\n",
    "\n",
    "The sort_values() method has a **kind** parameter that allows you to specify which sorting algorithm to use. The available options are:\n",
    "\n",
    "`quicksort` (This is the default)\n",
    "`mergesort`\n",
    "`heapsort`\n",
    "This can be useful if you are working with very large datasets and need a specific sorting algorithm.\n",
    "```c\n",
    "bio_data.sort_values(by='Seat_No', kind='mergesort')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb557fa8",
   "metadata": {},
   "source": [
    "### G. Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c13ea",
   "metadata": {},
   "source": [
    "When it comes to data analysis, grouping and aggregating the data is very useful for insight gathering.\n",
    "\n",
    "In this section, I will be creating a custom dataset manually to illustrate the examples.\n",
    "\n",
    "Before that,lets explain some concepts.\n",
    "For grouping in pandas, we make use of the `groupby()` function. This allows for quick analysis and summarization of our dataset regardless of the size.\n",
    "\n",
    "How does it work? The function splits thedataset into groups based on the selected column and _applies a function_ to each of the groups, then combine the results.\n",
    "\n",
    "What are the functions that are applied to it? They are the aggregation functions,\n",
    "we have the `.agg({})` method and other aggragation functions, which include;\n",
    "\n",
    "```c\n",
    ".sum() #Sum of values\n",
    ".mean() #Mean of values\n",
    ".median() #Median value\n",
    ".count() #Number of non-null values\n",
    ".min() #Minimum value\n",
    ".max() #Maximum value\n",
    ".std() #Standard deviation\n",
    ".var() #Variance\n",
    ".nunique() #Number of unique values\n",
    ".get_group() # To retrieve a single group by key\n",
    "```\n",
    "The `.agg({})` takes in a key-value pair  of column name and an aggregation function as an argument which could be one or more depending on what you are working on. When using the aggregating functions with the agg({}) method dictionary we dont usually add the round brackets.\n",
    "\n",
    "Lets create the dataset for our pratice example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0377d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets manually create a bio_data sample data\n",
    "bio = {\n",
    "    'First_Name': ['Emeka', 'Aisha', 'Ayo', 'Chinedu', 'Fatima', 'Ibrahim', 'Ngozi', 'Tolu', 'Olamide', 'Yusuf',\n",
    "                   'Ada', 'Kunle', 'Mercy', 'Segun', 'Zainab', 'Donald', 'Kemi', 'Usman', 'Funmi', 'Chika'],\n",
    "    'Last_Name': ['Julius', 'Bello', 'Adewale', 'Godswill', 'Abubakar', 'David', 'Collins', 'Ogunleye', 'Adepoju', 'Garba',\n",
    "                  'Umeh', 'Ojo', 'Musa', 'Balogun', 'Mohammed', 'Obi', 'Adebayo', 'Suleiman', 'Williams', 'Micheal'],\n",
    "    'Gender': ['Male', 'Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Male', 'Male',\n",
    "               'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Male'],\n",
    "    'Seat_No': range(101, 121),\n",
    "    'City': ['Lagos', 'Abuja', 'Ibadan', 'Enugu', 'Kano', 'Benin', 'Port Harcourt', 'Abeokuta', 'Benin', 'Abeokuta',\n",
    "             'Lagos', 'Abeokuta', 'Lagos', 'Ibadan', 'Abuja', 'Port Harcourt', 'Benin', 'Jos', 'Calabar', 'Onitsha'],\n",
    "    'Course_Track': ['Data Science', 'Cloud Computing', 'Cybersecurity', 'AI', 'Data Science', 'Cloud Computing',\n",
    "                     'Web Dev', 'AI', 'Cybersecurity', 'AI', 'Data Science', 'Web Dev',\n",
    "                     'Cybersecurity', 'AI', 'Cloud Computing', 'Data Science', 'Web Dev', 'Data Science',\n",
    "                     'Data Science', 'Cloud Computing'],\n",
    "    'PC_make': ['HP', 'Dell', 'HP', 'Asus', 'Apple', 'HP', 'Dell', 'Lenovo', 'Asus', 'Apple',\n",
    "                'HP', 'Dell', 'Lenovo', 'Asus', 'Dell', 'HP', 'Dell', 'Lenovo', 'Asus', 'Apple'],\n",
    "    'PC_Os': ['Windows', 'Linux', 'Windows', 'Windows', 'Linux', 'MacOS', 'Windows', 'Linux', 'MacOS', 'Windows',\n",
    "              'Linux', 'MacOS', 'Windows', 'Linux', 'MacOS', 'Windows', 'Linux', 'MacOS', 'Windows', 'Linux'],\n",
    "    'Feedback': ['Good', 'Excellent', 'Excellent', 'Good', 'Poor', 'Excellent', 'Good', 'Average', 'Good', 'Excellent',\n",
    "                 'Good', 'Poor', 'Average', 'Excellent', 'Good', 'Average', 'Excellent', 'Good', 'Good', 'Excellent']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets convert it to dataframe first\n",
    "bio_data2 = pd.DataFrame(bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094e368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af921ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets save it as a CSV file\n",
    "bio_data2.to_csv(\"bio_data2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e541c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_data2[\"Course_Track\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ad522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the total numbers of students taking each track?\n",
    "\n",
    "track_count = bio_data2.groupby(\"Course_Track\").agg({\"First_Name\":\"count\"})\n",
    "track_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the total number of students having the same numbers of PC_make\n",
    "bio_data2.groupby(\"PC_make\")[\"PC_make\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bio_data2.groupby('Course_Track').agg({'First_Name': 'count', 'PC_make': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c65b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What city are track from each track from?\n",
    "bio_data2.groupby('Course_Track').agg({'City': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What types of OS do students in each track use?\n",
    "bio_data2.groupby('Course_Track').agg({'PC_Os': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84cbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the most common course among the female students?\n",
    "female_group = bio_data2.groupby('Gender').get_group('Female')\n",
    "female_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b73154",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_group[\"Course_Track\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd3af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_size= bio_data2.groupby(\"Gender\").size()\n",
    "gender_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_size= bio_data2.groupby(\"Course_Track\").size()\n",
    "gender_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc87942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will help you to search and return the index of the specified group member\n",
    "\n",
    "#by_city = bio_data2.groupby(\"City\")\n",
    "#by_city.groups[\"Lagos\"]\n",
    "\n",
    "# or\n",
    "\n",
    "bio_data2.groupby(\"City\").groups[\"Lagos\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6a593",
   "metadata": {},
   "source": [
    "### H. Data Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea40a5",
   "metadata": {},
   "source": [
    "Reshaping data is a key part of data manipulation in pandas. It involves changing the layout or structure of the dataframe without altering the data.\n",
    "\n",
    "Below are a few, if you are curious, you can do a little bit of research on reshaping pandas dataframe.\n",
    "\n",
    "```c\n",
    "pivot() #This is used for reshaping the dataframe. It summerizes you table just like it is in excel spreadsheet.\n",
    "```\n",
    "\n",
    "\n",
    "```c\n",
    "pivot_table() #\n",
    "```\n",
    "\n",
    "```c\n",
    "melt() # converts dataframe from wide format to long format\n",
    "```\n",
    "\n",
    "```c\n",
    ".T # This is used for transposing your dataframe, that is, swapping the rows and the columns\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee9dde",
   "metadata": {},
   "source": [
    "Let's take one example here, if time permits, we will solve more examples using a dataset where we can apply this concept.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that is just an illustration of what is possible. It does not make sense to take the mean of Seat_No\n",
    "pivot_table = pd.pivot_table(bio_data2,\n",
    "                             index='Gender',\n",
    "                             columns='Course_Track',\n",
    "                             values='Seat_No',\n",
    "                             aggfunc='mean')\n",
    "print(\"Pivot Table of Average Seat_No by Gender and Course_Track:\")\n",
    "pivot_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEts transpose this\n",
    "pivot_table.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f9c65",
   "metadata": {},
   "source": [
    "### I. Merging and Joining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18af9d2",
   "metadata": {},
   "source": [
    "Both merging and joining are important techniques that allows you to combine two or more DataFrames based on common columns or indexes.\n",
    "\n",
    "I will list examples of those functions below and their use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948bcca",
   "metadata": {},
   "source": [
    "```\n",
    "pd. merge()\n",
    "```\n",
    "The merge function give us the SQL feel of joining. We can do inner, left, right, and outer join.\n",
    "Using merge, we must join both dataframes usinga common column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42e538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets add more details to our bio_data2 dataset by create a new one.\n",
    "\n",
    "\n",
    "\n",
    "course_data = {\n",
    "    'Course_Track': ['Data Science', 'Web Dev', 'Cybersecurity', 'AI', 'Cloud Computing'],\n",
    "    'Duration': ['8 months', '4 months', '5 months', '7 months', '6 months'],\n",
    "    'Fee': [600000, 350000, 450000, 550000, 500000]\n",
    "}\n",
    "course_df = pd.DataFrame(course_data)\n",
    "\n",
    "# both bio_data2 and course_data have \"Course_Track\" in common\n",
    "\n",
    "# Merge the two DataFrames on Course_Track (inner join by default)\n",
    "merged_df = pd.merge(bio_data2, course_df, on='Course_Track')\n",
    "print(\"Merged DataFrame (Inner Join on Course_Track):\")\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e2e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join: keep all rows from df\n",
    "left_joined = pd.merge(bio_data2, course_df, on='Course_Track', how='left')\n",
    "print(\"Left Joined DataFrame:\")\n",
    "left_joined.head()\n",
    "\n",
    "#Observe the output, it seems to be the same with the one above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c9470d",
   "metadata": {},
   "source": [
    "____________________________________________________\n",
    "**Hands On Practice**\n",
    "\n",
    "Try out both right and outer join. Ensure to observe the output and note anything thats seems usual or unusual.\n",
    "___________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581bb7e",
   "metadata": {},
   "source": [
    "There is also another function called .join() method;\n",
    "\n",
    "```c\n",
    ".join()\n",
    "```\n",
    "This method comes handy when you want to join usinh index. It a convinient way to combine DataFrames that share a common index.\n",
    "\n",
    "Lets create a new dataset and try joining it with ouir existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d0688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a city DataFrame with details for each unique city in your bio dataset\n",
    "city_data = {\n",
    "    'City': ['Lagos', 'Abuja', 'Ibadan', 'Enugu', 'Kano', 'Benin', 'Port Harcourt', 'Abeokuta', 'Jos', 'Calabar', 'Onitsha'],\n",
    "    'Population': [14000000, 3000000, 5000000, 4000000, 3500000, 2000000, 2500000, 800000, 600000, 500000, 900000],\n",
    "    'Region': ['South West', 'Federal Capital Territory', 'South West', 'South East', 'North West',\n",
    "               'South South', 'South South', 'South West', 'North Central', 'South South', 'South East']\n",
    "}\n",
    "\n",
    "city_df = pd.DataFrame(city_data)\n",
    "\n",
    "# Lets set index for the dataset before joining\n",
    "df_indexed = city_df.set_index(\"City\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da907600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets join this with merged_df\n",
    "\n",
    "joined_df = df_indexed.join(merged_df, how='left')\n",
    "print(\"Joined DataFrame using .join():\")\n",
    "joined_df.head()\n",
    "\n",
    "# Ensure to note the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bff91b",
   "metadata": {},
   "source": [
    "**End of class Assignment**\n",
    "\n",
    "1. https://www.openml.org/data/download/1586202/phpr1uf8O\n",
    "2. https://www.openml.org/data/download/29/dataset_29_credit-a.arff\n",
    "3. https://www.openml.org/data/download/1595261/phpMawTba\n",
    "4. https://drive.google.com/file/d/11cmclsGbfidJ-ETq5bEK302wK5TyUa8C/view?usp=drive_link\n",
    "\n",
    "Download any two of the dataset above. Apply what you have learnt so far on the dataset. If you are curious and wishes to explore, you can go overboard."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
