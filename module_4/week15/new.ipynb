{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "983f6c1f",
   "metadata": {},
   "source": [
    "# 1. Introduction to the Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741499d6",
   "metadata": {},
   "source": [
    "Welcome! This notebook will guide you through building your very first deep learning algorithm, the **Perceptron**, from scratch.\n",
    "\n",
    "Perceptrons were one of the first algorithms discovered in the field of AI. Their significance was that they raised the hopes and expectations for the field of neural networks. A Perceptron is a machine learning algorithm that uses a single node (or \"neuron\") to predict a class label for a row of data. It's the simplest possible type of neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eff544",
   "metadata": {},
   "source": [
    "### The Four Components of a Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23165f31",
   "metadata": {},
   "source": [
    "A Perceptron has four main parts. Think of it as a simple decision-making process:\n",
    "\n",
    "1.  **Input Values ($x$):** This is your data. For example, in our case, we'll have two input values, `x1` and `x2`.\n",
    "2.  **Weights ($w$) and Bias ($b$):**\n",
    "    -   **Weights:** Each input value has a corresponding \"weight\". A weight represents how important that input is for the final decision. A bigger weight means that input matters more.\n",
    "    -   **Bias:** The bias is an extra value that helps the model make a decision. \n",
    "    -   **Learning** is simple the process of finding the perfect set of weights and bias.\n",
    "3.  **Net Sum ($z$):** This is the first calculation the Perceptron does. It multiplies each input by its weight, sums them all up, and then adds the bias.\n",
    "\n",
    "    $z = (x_1 \\cdot w_1) + (x_2 \\cdot w_2) + ... + b$\n",
    "\n",
    "4.  **Activation Function:** This is the final step. The Perceptron takes the `Net Sum` ($z$) and passes it through a simple function to make a final, binary decision (0 or  1).\n",
    "    *   The simplest activation function is a **step function**\n",
    "    *   If the `Net Sum` ($z$) is greater than 0, predict **1**.\n",
    "    *   Otherwise, predict **0**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf8f84",
   "metadata": {},
   "source": [
    "# 2. Setup and Creating the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a65d6a",
   "metadata": {},
   "source": [
    "First, let's import the libraries we'll need.\n",
    "\n",
    "-   `numpy`: for numerical operations.\n",
    "-   `pandas`: to easily look at our data in a table.\n",
    "-   `matplotlib`: for plotting our data.\n",
    "-   `sklearn.datasets.make_classification`: a handy function to create a simple, fake dataset for us to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f50bffc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m \n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m \n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_classification \n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import make_classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f34d5",
   "metadata": {},
   "source": [
    "### Creating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4401f9",
   "metadata": {},
   "source": [
    "Here we generate a simulated dataset using scikit-learn's `make_classification` function. This creates a dataset with 2 input features and binary target labels.\n",
    "\n",
    "We're asking for:\n",
    "\n",
    "-   `n_samples = 20`: 20 rows of data\n",
    "-   `n_features = 2`: 2 input features (we'll call them `x1` and `x2`).\n",
    "-   `n_informative = 1`: only 1 of the features is _actually_ useful for telling the classes apart.\n",
    "-   `n_redundant = 0`: no extra, useless features.\n",
    "-   `n_clusters_per_class = 1`: each class (0 and 1) is just one single \"blob\" of data.\n",
    "-   `random_state = 1`: this ensures that if you run this code, you get the _exact same_ \"random\" data that I do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab6466",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets = make_classification(n_samples = 20,\n",
    "                                        n_features = 2, \n",
    "                                        n_informative = 1,\n",
    "                                        n_redundant = 0,\n",
    "                                        n_clusters_per_class = 1,\n",
    "                                        random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07a25b",
   "metadata": {},
   "source": [
    "Let's put this data into a `pandas` DataFrame to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e90e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = features, columns = ['x1', 'x2'])\n",
    "df['targets'] = targets\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc7593c",
   "metadata": {},
   "source": [
    "Let's check the `shape` of our data. This tells us (row, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2bc911",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9c893",
   "metadata": {},
   "source": [
    "`np.bincount` is a quick way to count how many samples of each class we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae509c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981114e",
   "metadata": {},
   "source": [
    "This confirms we have 10 samples of Class 0 and 10 samples of Class 1. A nice, balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c0190",
   "metadata": {},
   "source": [
    "# 3. Visualizing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62520c11",
   "metadata": {},
   "source": [
    "We can visualize the dataset by plotting the two input features colored by the target class. This gives us a sense of how linearly separable the data is.\n",
    "\n",
    "A **linearly separable** dataset is one where you can draw a single straight line to separate the two classes. A Perceptron can _only_ solve problems that are linearly separable.\n",
    "\n",
    "As we can see below, our data isn't _perfectly_ separable, but there is an approximate linear decision boundary. Let's see if our Perceptron can find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    features[targets == 0, 0],\n",
    "    features[targets == 0, 1],\n",
    "    marker = 'P',\n",
    "    markersize = 10,\n",
    "    linestyle = '',\n",
    "    label = 'Class 0'\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    features[targets == 1, 0],\n",
    "    features[targets == 1, 1],\n",
    "    marker = '^',\n",
    "    markersize = 10,\n",
    "    linestyle = '',\n",
    "    label = 'Class 1'\n",
    ")\n",
    "\n",
    "plt.legend(loc = 2)\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlabel(\"Feature $x_1$\", fontsize = 12)\n",
    "plt.ylabel(\"Feature $x_2$\", fontsize = 12)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_module",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
