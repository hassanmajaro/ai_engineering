{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40acc390",
   "metadata": {},
   "source": [
    "## **Data Preprocessing for Machine Language**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ccf19",
   "metadata": {},
   "source": [
    "**Data Cleaning is Not Data Processing!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd9a457",
   "metadata": {},
   "source": [
    "Its worthwhile to know that data cleaning is different from data preprocessing. In the machine learning implementation pipeline, data cleaning comes first. As matter of emphasis, through more light on data cleaning.\n",
    "\n",
    "The process of identifying and correcting errors, inconsistencies and inaccuracies in raw data is data cleaning. The tasks you would most likely encounter in data cleaning may include;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3255e",
   "metadata": {},
   "source": [
    "-   Handling missing values.\n",
    "-   Removing duplicate rows or columns.\n",
    "-   Correcting inconsistencies (like typos and inconsistent cases)\n",
    "-   Handling outliers.\n",
    "-   Handling corrupt strings (unicode problems).\n",
    "-   Handling irrelevant data and more that you might have encountered or may likely encounter in your journey with working with data.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Other Conflicting Terms with \"Data Preprocessing\"**\n",
    "\n",
    "It is quite important to note that as you progress in your learning, practice and research, you would come across some big data lingo that might throw you in confusion, kind of wandereing what they mean... some of these terms include **data mining, data wrangling, data preparation, data transformation, data harmonization, data refinement, data shaping, data manipulation, data manicuring, data validation** etc.\n",
    "\n",
    "In your spare time, do well to take your time to learning their meaning, their similarities and difference with other related terms.\n",
    "\n",
    "But two of those terms will be differentiated from data preprocessing in a simple table to get us going before moving into data preprocessing proper.\n",
    "\n",
    "\n",
    "| **Feature** | **Data Wrangling** | **Data Preprocessing** | **Data Mining** |\n",
    "|-------------|--------------------|------------------------|-----------------|\n",
    "| **Purpose** | Preparing and structuring raw data | Transforming data into a format suitable for ML | Extracing insights and patterns |\n",
    "| **Focus** | Cleaning, transforming, and integrating data | Encoding, scaling, and feature selection | Finding hidden relationships in data (the complete ML pipeline) |\n",
    "| **Techniques** | Data cleaning, merging, reshaping | Normalization, encoding, feature extraction | Clustering, classification, regression, anomaly detection |\n",
    "| **End Goal** | Organized, structured data | Model ready dataset | Actionable insights for decision making |\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Data Preprocessing**\n",
    "\n",
    "In the Nigerian setting, when you see people cooking many varieties of dishes with big sets of pots. The next thing that comes to mind is \"What is the celebration?\", that is, they are most likely cooking for a party or an event. It is the same thing when it comes to data preprocessing. So in a lay mans' definition, we can say that data preprocessing is the preparing and cooking of your dataset for ML model building. I think this should be clear enought.\n",
    "\n",
    "If simplicity feels like a scam to you, lets subscribe to a little bit of complexity in our definition.\n",
    "\n",
    "Data preprocessing is the step in the machine learning pipeline where raw data is transformed into a structured, clean, and suitable format for model training. It ensures that data is compatible with machine learning algorithms by handling incosistencies, scaling, encoding, and feature selection.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Why Should We Preprocess Data Before Building The ML Model?**\n",
    "\n",
    "**NOTE:** _I will introduce some new terms here, don't get worried if you don't understand them yet, but is good you are aware of their existence. I will bolden them for emphasis_\n",
    "\n",
    "Lets break it donw, the effectiveness of our model is at the mercy of how well our features are engineered, and **feature engineering** is at the mercy of data preprocessing. Data preprocessing is crucial in machine learning because raw data is often incomplete, inconsistent, and noisy. Without proper preprocessing, **ML Algorithms** may learn incorrect patterns, leading to poor performance.\n",
    "\n",
    "\n",
    "So lets answer the question now.\n",
    "1.  To improve data quality: After cleaning data **features** might still contain errors, inconsistencies and missing features that can affect the performance of the **model**. So preprocessing prepares the dataset for **feature selection** helping.\n",
    "2.  Enhance Model Performance: Most ML algorithms learn better when the features are **scaled, normalized** and structured properly. So proper preprocessing ensures that features contribute meaningfully to **predictions.**\n",
    "3.  Prevent Models fro **Overfitting, Underfitting, High Variance** and **Bias**: Handling **imbalance datasets** prevents the model from being biased towards the dominant **class**. So proper preprocessing ensures that the features contributes meaningfully to predictions of the model.\n",
    "4.  Ensures Algorighm Compatibility: Many ML algorithms require numeric inputs (e.g., **encoding** categorical variables). Some algorithms, like KNN and neural networks, are sensitive to scale, requiring normaliztion.\n",
    "5.  Improves Model Accuracy and Efficiency: Well preprocessed data helps models learn better patterns, leading to improved **accuracy** and **generalization**. Reduces **computational complexity** by eliminating **irrelevant features**.\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Technical Terms Used in Data Preprocessing**\n",
    "\n",
    "Who doesn't admire professional who sounds technical and at the same time reasonable when delivering talks that have to do with their fields? I do admire them, don't know about you... So don't be overwhelmed seeing the next table, I just made life easire for you. When you konw and understand this stuffs, you are like 70% away from being a professional ML hypeman, trust me!\n",
    "\n",
    "You really don't have to know all of them, we will obviously not talk about most of them, and for some you may not use it all in your ML practice. But keep it handy as a cheatsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbd9b9",
   "metadata": {},
   "source": [
    "| **Term** | **Meaning** | **Implementation (Python)** |\n",
    "|----------|-------------|-----------------------------|\n",
    "| **Missing Value Imputation** | Strategies for filing in missing data | `df.fillna()` or `KNNImputer()` (from `sklearn`) |\n",
    "| **Mean/Median/Mode Imputation** | Replacing missing values with the average, median or mode | `df.fillna(df.mean())`, `df.fillna(df.median())` |\n",
    "| **KNN Imputation** | Using similar data points to fill in missing values | `KNNImputer()` (from `sklearn`) |\n",
    "| **Regression Imputation** | Predicting missing values using a regression model | Custom implementation using `LinearRegression()` |\n",
    "| **Multiple Imputation** | Creating multiple plausible versions of data and combining them | `IterativeImputer()` (from `sklearn`) |\n",
    "| **Outlier Detection** | Identifying and handling extreme values | `zscore()`, `IQR method` |\n",
    "| **Z-score Method** | Identifying outliers based on standard deviation | `zscore(df['col'])` |\n",
    "| **IQR Method** | Identifying outliers based on interquartile range | `IQR = df['col'].quantile(0.75) - df['col'].quantile(0.25)` |\n",
    "| **Box Plots** | Visual representation of data distribution with outliers | `sns.boxplot(x='col', data=df)` |\n",
    "| **Winsorizing/Clipping** | Limiting extreme values to a specified threshold | `winsorize()` from `scipy.stats` |\n",
    "| **Data Deduplication** | Removing duplicate records | `df.drop_duplicates()` |\n",
    "| **Noise Removal** | Reducing random errors or noise in data | `smooth()` or `scipy.signal.savgol_filter()` |\n",
    "| **Smoothing techniques** | Applying filters to reduce random noise in time-series data | `moving_average()`, `SavitzkyGolay()` (from `scipy`) |\n",
    "| **Data Type Conversion** | Changing data types for consistency | `df['col'] = df['col'].astype(int)` |\n",
    "| **Data Transformation** | Changing the format or structure of the data | `np.log()`, `BoxCox()` (from `scipy`) |\n",
    "| **Normalization** | Scaling data to a specific range (usually 0 to 1) | `MinMaxScaler() (from `sklearn`)\n",
    "| **Min-Max Scaling** | Scaling data between 0 and 1 | `MinMaxScaler().fit_transform(df)` |\n",
    "|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa34ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
